{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: <module 'tensorflow._api.v2.version' from '/Users/franklinglance/anaconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/_api/v2/version/__init__.py'>\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 15:34:21.686375: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"INVALID_ARGUMENT: Error executing an HTTP request: HTTP response code 400 with body '{\n",
      "  \"error\": \"invalid_grant\",\n",
      "  \"error_description\": \"Token has been expired or revoked.\"\n",
      "}'\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to ~/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a9df4d8e694f4485cd1fea7672f87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to ~/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "WARNING:tensorflow:AutoGraph could not transform <function normalize_img at 0x280d9f4c0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function normalize_img at 0x280d9f4c0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 15:34:23.267122: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-08 15:34:23.267320: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:tensorflow:AutoGraph could not transform <function normalize_img at 0x280d9f4c0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function normalize_img at 0x280d9f4c0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function normalize_img at 0x280d9f4c0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function normalize_img at 0x280d9f4c0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 15:34:23.670199: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-07-08 15:34:23.670666: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - ETA: 0s - loss: 0.1566 - accuracy: 0.9536"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 15:34:30.807843: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 8s 13ms/step - loss: 0.1566 - accuracy: 0.9536 - val_loss: 0.0514 - val_accuracy: 0.9831\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0455 - accuracy: 0.9858 - val_loss: 0.0438 - val_accuracy: 0.9866\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0288 - accuracy: 0.9910 - val_loss: 0.0351 - val_accuracy: 0.9884\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.0496 - val_accuracy: 0.9850\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 0.0353 - val_accuracy: 0.9891\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.0411 - val_accuracy: 0.9878\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.0340 - val_accuracy: 0.9900\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.0381 - val_accuracy: 0.9897\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0483 - val_accuracy: 0.9889\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0532 - val_accuracy: 0.9872\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0427 - val_accuracy: 0.9902\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0397 - val_accuracy: 0.9906\n",
      "CPU times: user 45.6 s, sys: 29.1 s, total: 1min 14s\n",
      "Wall time: 1min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2875cb490>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"TensorFlow version:\", tf.version)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices('GPU')\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: uint8 -> float32.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "batch_size = 128\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(batch_size)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(batch_size)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu'),\n",
    "  tf.keras.layers.Conv2D(64, kernel_size=(3, 3),\n",
    "                 activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#   tf.keras.layers.Dropout(0.25),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "#   tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=12,\n",
    "    validation_data=ds_test,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.9.2\n",
      "Keras Version: 2.9.0\n",
      "\n",
      "Python 3.9.12 (main, Jun  1 2022, 06:34:44) \n",
      "[Clang 12.0.0 ]\n",
      "Pandas 1.4.2\n",
      "Scikit-Learn 1.0.2\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "\n",
    "from tensorflow import keras as K\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {K.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "499d487e9240018a7744f386b0d3493e4cb53ffecf411fc7fb01c2b24da743ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
